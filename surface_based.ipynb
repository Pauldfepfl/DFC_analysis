{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tvb.simulator.lab as tsl\n",
    "import mne_connectivity \n",
    "import tvb\n",
    "from scipy import signal\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy \n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import pandas as pd\n",
    "import netplotbrain\n",
    "\n",
    "import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFC_visu_pipeline(data, cor_method, num_clusters=3, window_size=2000, overlap=1000,tmax=30, intrahemispheric=False, square=[0,0],animated_visu=True,ts=0.5):\n",
    "    '''\n",
    "    This function performs visualisations regarding Dynamical Functional connectivity (DFC). \n",
    "\n",
    "    ------------\n",
    "    INPUTS\n",
    "    ------------\n",
    "\n",
    "    data : array_like, shape = (signal_duration/timestep,num_regions) \n",
    "        The signal data, typically eeg signal or source level signal. \n",
    "    cor_method : string\n",
    "        The correlation method to build the connectivity matrices. Can be chosen over 'Pearson', 'Spearman', 'Coherence', 'Phase-lock' and 'wpli'.\n",
    "    num_clusters : int, default = 3\n",
    "        Number of clusters for the k-means clustering.\n",
    "    window_size : int, default = 2000  \n",
    "        window_duration[ms]/timestep[ms]\n",
    "    overlap : int or float, default = 1000 \n",
    "        Time of overlap [ms] between two succint windows. \n",
    "    tmax : int, default = 30\n",
    "        Time of the simulation, for visualisation purpose. \n",
    "    intrahemispheric : bool, default = False\n",
    "        Visualisation of clustering of a single square of the connectivity matrix. \n",
    "    square : 2x2 list, default = [0,0]\n",
    "        If intrahemispheric = True, specifies the square of the matrix to perform the analysis on. \n",
    "    animated_visu : bool, default = True\n",
    "        Plot and save an animated plot showing the evolution of correlation matrices and pca visualisation. \n",
    "\n",
    "\n",
    "    ------------\n",
    "    OUTPUTS\n",
    "    ------------\n",
    "    closest_mats : array_like, shape = (num_clusters, num_regions,num_regions)\n",
    "        Closest connectivity matrix to every cluster. \n",
    "    most_repeating_states : array_like, shape = (num_clusters, num_regions,num_regions)\n",
    "         Kmeans clusters centroids. \n",
    "    correlation_matrices : array_like, shape = (num_windows, num_regions,num_regions)\n",
    "        Set of correlation matrics, one per window. \n",
    "    cluster_labels : list, len = num_clusters\n",
    "        Cluster labels.\n",
    "    distances : array_like, shape = (num_clusters, num_windows)\n",
    "         Matrix storing the distances between each connectivity matrix and each cluster. \n",
    "    pca : Sklearn PCA object.\n",
    "        PCA object used for the connectivity matrices dimension reduction.   \n",
    "    reduced_data : array_like\n",
    "        3D PCA reduced data.\n",
    "    '''\n",
    "    closest_mats,most_repeating_states, correlation_matrices, cluster_labels,num_clusters = fn.build_FCmat(data,cor_method,num_clusters,window_size,overlap,tmax,intrahemispheric,square=square)\n",
    "    distances = fn.compute_clst_dist(most_repeating_states, correlation_matrices, cluster_labels,tmax,num_clusters) \n",
    "    pca, reduced_data = fn.plot_PCA(correlation_matrices, most_repeating_states, cluster_labels,num_clusters)\n",
    "    if animated_visu : \n",
    "        fn.animated_plot(correlation_matrices,reduced_data,cluster_labels)\n",
    "\n",
    "    return closest_mats,most_repeating_states, correlation_matrices, cluster_labels, distances, pca, reduced_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = 'D:/Fariba/SC'\n",
    "path_save = f'D:/Timing_optimisation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before stim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/15Hz/'\n",
    "for i in [5]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment11.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=30000\n",
    "\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats5,most_repeating_states5, correlation_matrices5, cluster_labels5, distances5, pca5, reduced_data5 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, num_clusters, figsize=(15, 5))\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # Position of the colorbar\n",
    "\n",
    "for a in range(len(closest_mats5)):\n",
    "    im = axs[a].imshow(closest_mats5[a], cmap='viridis')\n",
    "    axs[a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[a].axhline(y=34, color='white', linewidth=2)\n",
    "    axs[a].axhline(y=49, color='white', linewidth=2)\n",
    "    axs[a].axvline(x=34, color='white', linewidth=2)\n",
    "    axs[a].axvline(x=49, color='white', linewidth=2)\n",
    "\n",
    "    if a == 0:\n",
    "        axs[a].text(-2.8, 25, 'Left Cortical', color='black', ha='center', rotation='vertical')\n",
    "        axs[a].text(-2.8, 50, 'Subcortical', color='black', ha='center', rotation='vertical')\n",
    "        axs[a].text(-2.8, 78, 'Right Cortical', color='black', ha='center', rotation='vertical')\n",
    "\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "fig.suptitle(f'Closest matrix to the cluster centers, Stroke', y=0.92)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/15Hz/'\n",
    "for i in [7]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment11.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=30000\n",
    "\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats7,most_repeating_states7, correlation_matrices7, cluster_labels7,distances7, pca7, reduced_data7 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/15Hz/'\n",
    "for i in [10]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment11.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=30000\n",
    "\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats10,most_repeating_states10, correlation_matrices10, cluster_labels10,distances10, pca10, reduced_data10 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matrices figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, num_clusters, figsize=(15, 10))\n",
    "\n",
    "# Plot closest_mats5\n",
    "for a in range(len(closest_mats5)):\n",
    "    im = axs[0, a].imshow(closest_mats5[a], cmap='viridis')\n",
    "    axs[0, a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[0, a].axhline(y=34, color='white', linewidth=2)\n",
    "    axs[0, a].axhline(y=49, color='white', linewidth=2)\n",
    "    axs[0, a].axvline(x=34, color='white', linewidth=2)\n",
    "    axs[0, a].axvline(x=49, color='white', linewidth=2)\n",
    "\n",
    "    \n",
    "    if a == 0:\n",
    "        axs[0, a].text(-2.8, 25, 'Left Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[0, a].text(-2.8, 50, 'Subcortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[0, a].text(-2.8, 78, 'Right Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "axs[0, 1].set_title('Stroke',fontsize=22)  # Add title for axs[0]\n",
    "\n",
    "# Plot closest_mats7\n",
    "for a in range(len(closest_mats7)):\n",
    "    im = axs[1, a].imshow(closest_mats7[a], cmap='viridis')\n",
    "    axs[1, a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[1, a].axhline(y=34, color='white', linewidth=2)\n",
    "    axs[1, a].axhline(y=49, color='white', linewidth=2)\n",
    "    axs[1, a].axvline(x=34, color='white', linewidth=2)\n",
    "    axs[1, a].axvline(x=49, color='white', linewidth=2)\n",
    "\n",
    "    if a == 0:\n",
    "        axs[1, a].text(-2.8, 25, 'Left Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[1, a].text(-2.8, 50, 'Subcortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[1, a].text(-2.8, 78, 'Right Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "axs[1, 1].set_title('Healthy', fontsize=22)  # Add title for axs[1]\n",
    "\n",
    "# Place colorbar at the bottom horizontally\n",
    "cbar_ax = fig.add_axes([0.15, 0.05, 0.7, 0.02])\n",
    "\n",
    "fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "ext_data=np.concatenate((correlation_matrices5,most_repeating_states5))\n",
    "data=np.array(ext_data).reshape(len(correlation_matrices5)+num_clusters,len(correlation_matrices5[0])**2)\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "\n",
    "\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "u=np.diff(reduced_data[:-num_clusters, 0])\n",
    "v=np.diff(reduced_data[:-num_clusters, 1])\n",
    "pos_x = reduced_data[:-num_clusters-1, 0] + u/2\n",
    "pos_y = reduced_data[:-num_clusters-1, 1] + v/2\n",
    "norm = np.sqrt(u**2+v**2) \n",
    "\n",
    "\n",
    "axs[0].plot(reduced_data[:-num_clusters, 0], reduced_data[:-num_clusters, 1], linewidth=0.5)\n",
    "sns.scatterplot(x=reduced_data[:-num_clusters, 0], y=reduced_data[:-num_clusters, 1], size=10, hue=cluster_labels5, palette='Set1', ax=axs[0])\n",
    "#axs[0].legend(loc='upper left')\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = reduced_data[-num_clusters:]\n",
    "sns.scatterplot(\n",
    "    x=centroids[:, 0],\n",
    "    y=centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=600,\n",
    "    hue=np.linspace(0, num_clusters-1, num_clusters),\n",
    "    palette='Set1',\n",
    "    legend=False,\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "axs[0].quiver(pos_x, pos_y, u/norm, v/norm, angles=\"xy\", zorder=5, pivot=\"mid\", width=0.001, headwidth=20)\n",
    "\n",
    "axs[0].set_title(\n",
    "    \"Stroke\", fontsize=22\n",
    ")\n",
    "axs[0].set_xlim(x_min-7, x_max)\n",
    "axs[0].set_xticks(())\n",
    "axs[0].set_yticks(())\n",
    "\n",
    "ext_data=np.concatenate((correlation_matrices7,most_repeating_states7))\n",
    "data=np.array(ext_data).reshape(len(correlation_matrices7)+num_clusters,len(correlation_matrices7[0])**2)\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "\n",
    "\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "u=np.diff(reduced_data[:-num_clusters, 0])\n",
    "v=np.diff(reduced_data[:-num_clusters, 1])\n",
    "pos_x = reduced_data[:-num_clusters-1, 0] + u/2\n",
    "pos_y = reduced_data[:-num_clusters-1, 1] + v/2\n",
    "norm = np.sqrt(u**2+v**2) \n",
    "\n",
    "\n",
    "axs[1].plot(reduced_data[:-num_clusters, 0], reduced_data[:-num_clusters, 1], linewidth=0.5)\n",
    "sns.scatterplot(x=reduced_data[:-num_clusters, 0], y=reduced_data[:-num_clusters, 1], size=10, hue=cluster_labels7, palette='Set1', ax=axs[1])\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = reduced_data[-num_clusters:]\n",
    "sns.scatterplot(\n",
    "    x=centroids[:, 0],\n",
    "    y=centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=600,\n",
    "    hue=np.linspace(0, num_clusters-1, num_clusters),\n",
    "    palette='Set1',\n",
    "    legend=False,\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[1].quiver(pos_x, pos_y, u/norm, v/norm, angles=\"xy\", zorder=5, pivot=\"mid\", width=0.001, headwidth=20)\n",
    "\n",
    "axs[1].set_title(\n",
    "    \"Healthy\", fontsize=22\n",
    ")\n",
    "axs[1].set_xlim(x_min-7, x_max)\n",
    "axs[1].set_xticks(())\n",
    "axs[1].set_yticks(())\n",
    "axs[1].get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(20, 15))\n",
    "time = np.linspace(1,30,len(correlation_matrices5))\n",
    "\n",
    "colors=['red','blue','green','orange','black','purple']\n",
    "\n",
    "\n",
    "for a in range(num_clusters):    \n",
    "    axs[0].plot(time, distances5[a, :], label=f'State {str(a)}', c=colors[a])\n",
    "    axs[1].plot(time, distances7[a, :], label=f'State {str(a)}', c=colors[a])\n",
    "\n",
    "\n",
    "axs[0].set_title('Stroke', fontsize=30)\n",
    "axs[0].set_ylabel('1-distance',  fontsize=24)\n",
    "axs[0].legend(fontsize=20)\n",
    "axs[0].tick_params(axis='y', labelsize=18)\n",
    "axs[0].tick_params(axis='x', labelsize=0)\n",
    "axs[0].set_ylim(0.6,0.75)\n",
    "\n",
    "axs[1].set_title('Healthy', fontsize=30)\n",
    "axs[1].set_xlabel('Time [s]', fontsize=22)\n",
    "axs[1].set_ylabel('1-distance',  fontsize=22)\n",
    "axs[1].set_ylim(0.6,0.75)\n",
    "\n",
    "axs[1].tick_params(axis='x', labelsize=18)\n",
    "axs[1].tick_params(axis='y', labelsize=18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, num_clusters, figsize=(25, 15))\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # Position of the colorbar\n",
    "time = np.linspace(1,30,len(correlation_matrices))\n",
    "colors=['red','blue','green','orange','black','purple']\n",
    "\n",
    "# Plot closest_mats5\n",
    "for a in range(len(closest_mats5)):\n",
    "    im = axs[0, a].imshow(closest_mats5[a], cmap='plasma')\n",
    "    axs[0, a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[0, a].axhline(y=34, color='white', linewidth=2)\n",
    "    axs[0, a].axhline(y=49, color='white', linewidth=2)\n",
    "    axs[0, a].axvline(x=34, color='white', linewidth=2)\n",
    "    axs[0, a].axvline(x=49, color='white', linewidth=2)\n",
    "\n",
    "    if a == 0:\n",
    "        axs[0, a].text(-2.8, 25, 'Left Cortical', color='black', ha='center', rotation='vertical')\n",
    "        axs[0, a].text(-2.8, 50, 'Subcortical', color='black', ha='center', rotation='vertical')\n",
    "        axs[0, a].text(-2.8, 78, 'Right Cortical', color='black', ha='center', rotation='vertical')\n",
    "axs[0, 1].set_title('Stroke')  # Add title for axs[0]\n",
    "\n",
    "# Plot closest_mats7\n",
    "for a in range(len(closest_mats7)):\n",
    "    im = axs[2, a].imshow(closest_mats7[a], cmap='plasma')\n",
    "    axs[2, a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[2, a].axhline(y=34, color='white', linewidth=2)\n",
    "    axs[2, a].axhline(y=49, color='white', linewidth=2)\n",
    "    axs[2, a].axvline(x=34, color='white', linewidth=2)\n",
    "    axs[2, a].axvline(x=49, color='white', linewidth=2)\n",
    "\n",
    "    if a == 0:\n",
    "        axs[2, a].text(-2.8, 25, 'Left Cortical', color='black', ha='center', rotation='vertical')\n",
    "        axs[2, a].text(-2.8, 50, 'Subcortical', color='black', ha='center', rotation='vertical')\n",
    "        axs[2, a].text(-2.8, 78, 'Right Cortical', color='black', ha='center', rotation='vertical')\n",
    "axs[2, 1].set_title('Healthy')  # Add title for axs[1]\n",
    "\n",
    "for a in range(num_clusters):\n",
    "    axs[1, 1].plot(time, distances5[a, :], label=str(a), c=colors[a])\n",
    "    axs[3, 1].plot(time, distances7[a, :], label=str(a), c=colors[a])\n",
    "\n",
    "# Set the limits of the y-axis for the distance plots\n",
    "axs[1, 1].set_ylim([0, 1])\n",
    "axs[3, 1].set_ylim([0, 1])\n",
    "\n",
    "# Remove unnecessary subplots\n",
    "axs[1, 0].remove()\n",
    "axs[3, 0].remove()\n",
    "axs[1, 2].remove()\n",
    "axs[3, 2].remove()\n",
    "\n",
    "# Set common x and y labels for the remaining subplots\n",
    "axs[1, 1].set_xlabel('Time [s]')\n",
    "axs[1, 1].set_ylabel('1 - Relative distance')\n",
    "axs[3, 1].set_xlabel('Time [s]')\n",
    "axs[3, 1].set_ylabel('1 - Relative distance')\n",
    "\n",
    "# Add legends to the remaining subplots\n",
    "axs[1, 1].legend()\n",
    "axs[3, 1].legend()\n",
    "\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "fig.suptitle(f'Comparison of network states without stimulation between stroke and healthy patient', y=0.92)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## During stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/15Hz/'\n",
    "for i in [5,10]:#[2,5,7,8,9,10,11,12]    \n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment11.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=30000\n",
    "    t2=60000\n",
    "\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats,most_repeating_states, correlation_matrices, cluster_labels,distances, pca12, reduced_data = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure poster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/15Hz/'\n",
    "for i in [7]:#[2,5,7,8,9,10,11,12]    \n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment11.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=30000\n",
    "    t2=60000\n",
    "\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats_stim,most_repeating_states_stim, correlation_matrices_stim, cluster_labels_stim,distances_stim, pca12_stim, reduced_data_stim = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, num_clusters, figsize=(15, 10))\n",
    "\n",
    "# Plot closest_mats5\n",
    "for a in range(len(closest_mats7)):\n",
    "    im = axs[0, a].imshow(closest_mats7[a], cmap='viridis')\n",
    "    axs[0, a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[0, a].axhline(y=34, color='white', linewidth=2)\n",
    "    axs[0, a].axhline(y=49, color='white', linewidth=2)\n",
    "    axs[0, a].axvline(x=34, color='white', linewidth=2)\n",
    "    axs[0, a].axvline(x=49, color='white', linewidth=2)\n",
    "    \n",
    "    # Outline the 13th row and 55th column\n",
    "    axs[0, a].axhline(y=12, color='red', linewidth=0.5)\n",
    "    axs[0, a].axvline(x=54, color='red', linewidth=0.5)\n",
    "    axs[0, a].axhline(y=14, color='red', linewidth=0.5)\n",
    "    axs[0, a].axvline(x=56, color='red', linewidth=0.5)\n",
    "\n",
    "    if a == 0:\n",
    "        axs[0, a].text(-2.8, 25, 'Left Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[0, a].text(-2.8, 50, 'Subcortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[0, a].text(-2.8, 78, 'Right Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "axs[0, 1].set_title('Before stimulation',fontsize=14)  # Add title for axs[0]\n",
    "\n",
    "# Plot closest_mats7\n",
    "for a in range(len(closest_mats_stim)):\n",
    "    im = axs[1, a].imshow(closest_mats_stim[a], cmap='viridis')\n",
    "    axs[1, a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[1, a].axhline(y=34, color='white', linewidth=2)\n",
    "    axs[1, a].axhline(y=49, color='white', linewidth=2)\n",
    "    axs[1, a].axvline(x=34, color='white', linewidth=2)\n",
    "    axs[1, a].axvline(x=49, color='white', linewidth=2)\n",
    "    \n",
    "    # Outline the 13th row and 54th column\n",
    "    axs[1, a].axhline(y=12, color='red', linewidth=0.5)\n",
    "    axs[1, a].axvline(x=54, color='red', linewidth=0.5)\n",
    "    axs[1, a].axhline(y=14, color='red', linewidth=0.5)\n",
    "    axs[1, a].axvline(x=56, color='red', linewidth=0.5)\n",
    "\n",
    "    if a == 0:\n",
    "        axs[1, a].text(-2.8, 25, 'Left Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[1, a].text(-2.8, 50, 'Subcortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[1, a].text(-2.8, 78, 'Right Cortical', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "axs[1, 1].set_title('During stimulation', fontsize=14)  # Add title for axs[1]\n",
    "\n",
    "# Place colorbar at the bottom horizontally\n",
    "cbar_ax = fig.add_axes([0.15, 0.05, 0.7, 0.02])\n",
    "\n",
    "fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "ext_data=np.concatenate((correlation_matrices_stim,most_repeating_states_stim))\n",
    "data=np.array(ext_data).reshape(len(correlation_matrices_stim)+num_clusters,len(correlation_matrices_stim[0])**2)\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "\n",
    "\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "u=np.diff(reduced_data[:-num_clusters, 0])\n",
    "v=np.diff(reduced_data[:-num_clusters, 1])\n",
    "pos_x = reduced_data[:-num_clusters-1, 0] + u/2\n",
    "pos_y = reduced_data[:-num_clusters-1, 1] + v/2\n",
    "norm = np.sqrt(u**2+v**2) \n",
    "\n",
    "\n",
    "axs[0].plot(reduced_data[:-num_clusters, 0], reduced_data[:-num_clusters, 1], linewidth=0.5)\n",
    "sns.scatterplot(x=reduced_data[:-num_clusters, 0], y=reduced_data[:-num_clusters, 1], size=10, hue=cluster_labels_stim, palette='Set1', ax=axs[0])\n",
    "#axs[0].legend(loc='upper left')\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = reduced_data[-num_clusters:]\n",
    "sns.scatterplot(\n",
    "    x=centroids[:, 0],\n",
    "    y=centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=600,\n",
    "    hue=np.linspace(0, num_clusters-1, num_clusters),\n",
    "    palette='Set1',\n",
    "    legend=False,\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "axs[0].quiver(pos_x, pos_y, u/norm, v/norm, angles=\"xy\", zorder=5, pivot=\"mid\", width=0.001, headwidth=20)\n",
    "\n",
    "axs[0].set_title(\n",
    "    \"Stroke\", fontsize=22\n",
    ")\n",
    "axs[0].set_xlim(x_min-7, x_max)\n",
    "axs[0].set_xticks(())\n",
    "axs[0].set_yticks(())\n",
    "\n",
    "ext_data=np.concatenate((correlation_matrices7,most_repeating_states7))\n",
    "data=np.array(ext_data).reshape(len(correlation_matrices7)+num_clusters,len(correlation_matrices7[0])**2)\n",
    "reduced_data = PCA(n_components=2).fit_transform(data)\n",
    "\n",
    "\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "u=np.diff(reduced_data[:-num_clusters, 0])\n",
    "v=np.diff(reduced_data[:-num_clusters, 1])\n",
    "pos_x = reduced_data[:-num_clusters-1, 0] + u/2\n",
    "pos_y = reduced_data[:-num_clusters-1, 1] + v/2\n",
    "norm = np.sqrt(u**2+v**2) \n",
    "\n",
    "\n",
    "axs[1].plot(reduced_data[:-num_clusters, 0], reduced_data[:-num_clusters, 1], linewidth=0.5)\n",
    "sns.scatterplot(x=reduced_data[:-num_clusters, 0], y=reduced_data[:-num_clusters, 1], size=10, hue=cluster_labels7, palette='Set1', ax=axs[1])\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = reduced_data[-num_clusters:]\n",
    "sns.scatterplot(\n",
    "    x=centroids[:, 0],\n",
    "    y=centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=600,\n",
    "    hue=np.linspace(0, num_clusters-1, num_clusters),\n",
    "    palette='Set1',\n",
    "    legend=False,\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[1].quiver(pos_x, pos_y, u/norm, v/norm, angles=\"xy\", zorder=5, pivot=\"mid\", width=0.001, headwidth=20)\n",
    "\n",
    "axs[1].set_title(\n",
    "    \"Healthy\", fontsize=22\n",
    ")\n",
    "axs[1].set_xlim(x_min-7, x_max)\n",
    "axs[1].set_xticks(())\n",
    "axs[1].set_yticks(())\n",
    "axs[1].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(25, 20))\n",
    "time = np.linspace(1,30,len(correlation_matrices))\n",
    "\n",
    "colors=['red','blue','green','orange','black','purple']\n",
    "\n",
    "\n",
    "for a in range(num_clusters):    \n",
    "    axs[0].plot(time, distances7[a, :], label=f'State {str(a)}', c=colors[a])\n",
    "    axs[1].plot(time, distances_stim[a, 4:], label=f'State {str(a)}', c=colors[a])\n",
    "\n",
    "\n",
    "axs[0].set_title('Before stimulation', fontsize=30)\n",
    "axs[0].set_xlabel('Time [s]', fontsize=24)\n",
    "axs[0].set_ylabel('1-Distance',  fontsize=24)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title('After stimulation', fontsize=30)\n",
    "axs[1].set_xlabel('Time [s]', fontsize=24)\n",
    "axs[1].set_ylabel('1-Distance',  fontsize=24)\n",
    "axs[1].legend()\n",
    "\n",
    "fig.suptitle(f'Proximity to each state over time', y=0.94,fontsize=35)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = 'D:/Fariba/SC'\n",
    "path_save = f'D:/Timing_optimisation'\n",
    "G=[7]\n",
    "#G=[1,1.5,2,3,4,5,6,7,8,9,10,12]\n",
    "for g in range(len(G)):\n",
    "    path_conn = 'D:/Fariba/SC'\n",
    "    path_save = f'D:/Timing_optimisation'\n",
    "    data = np.load(f'{path_save}/20minsim_dt_0.5_G_{7}_sigma_1e-07.npz')\n",
    "    data_time=data['traw_time']\n",
    "    delta_t = data_time[1]-data_time[0]\n",
    "    sf = 1/(delta_t*1e-3)\n",
    "    win = 1*sf\n",
    "\n",
    "    t1 = 1000\n",
    "    t2 = 2400000 #unit second\n",
    "    time_corr_id= np.where((data_time>=t1)*(data_time<=t2))\n",
    "    idc1 = time_corr_id[0][0]\n",
    "    idc2= time_corr_id[0][-1]\n",
    "    time_corr=data_time[idc1:idc2]\n",
    "    data_corr=data['traw_y1y2'][idc1:idc2]\n",
    "    print(np.array(data_corr).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats_temp,most_repeating_states_temp, correlation_matrices_temp, cluster_labels_temp,distances_temp, pca12_temp, reduced_data_temp = DFC_visu_pipeline(data_corr,meth,animated_visu=False, window_size=10000,overlap=5000,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca12_temp.components_\n",
    "    for comp in components : \n",
    "        plt.figure()\n",
    "        plt.imshow(comp.reshape(int(np.sqrt(len(comp))),int(np.sqrt(len(comp)))),cmap='bwr')\n",
    "        plt.colorbar();plt.clim([-0.05,0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCs(pca12_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, num_clusters, figsize=(15, 10))\n",
    "\n",
    "# Plot closest_mats5\n",
    "for a in range(len(closest_mats_temp)):\n",
    "    im = axs[ a].imshow(closest_mats_temp[a], cmap='viridis')\n",
    "    axs[ a].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    \n",
    "    # Add lines between lines and columns 34 and 49\n",
    "    axs[ a].axhline(y=37, color='white', linewidth=2)\n",
    "    axs[ a].axvline(x=37, color='white', linewidth=2)\n",
    "\n",
    "    \n",
    "    if a == 0:\n",
    "        axs[ a].text(-2.8, 33, 'Right hemisphere', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[ a].text(-2.8, 70, 'Left hemisphere', color='black', ha='center', rotation='vertical',fontsize=11)\n",
    "        axs[ a].text(18, 80, 'Right hemisphere', color='black', ha='center', rotation='horizontal',fontsize=11)\n",
    "        axs[ a].text(55, 80, 'Left hemisphere', color='black', ha='center', rotation='horizontal',fontsize=11)\n",
    "\n",
    "# Place colorbar on the right side vertically\n",
    "cbar_ax = fig.add_axes([0.92, 0.325, 0.02, 0.34])\n",
    "\n",
    "fig.colorbar(im, cax=cbar_ax, orientation='vertical')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data=np.concatenate((correlation_matrices_temp,most_repeating_states_temp))\n",
    "data=np.array(ext_data).reshape(len(correlation_matrices_temp)+num_clusters,len(correlation_matrices_temp[0])**2)\n",
    "pca_2d_temp=PCA(n_components=2)\n",
    "reduced_data = pca_2d_temp.fit_transform(data)\n",
    "\n",
    "\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "u=np.diff(reduced_data[:-num_clusters, 0])\n",
    "v=np.diff(reduced_data[:-num_clusters, 1])\n",
    "pos_x = reduced_data[:-num_clusters-1, 0] + u/2\n",
    "pos_y = reduced_data[:-num_clusters-1, 1] + v/2\n",
    "norm = np.sqrt(u**2+v**2) \n",
    "\n",
    "\n",
    "plt.plot(reduced_data[:-num_clusters, 0], reduced_data[:-num_clusters, 1],linewidth=0.5)\n",
    "sns.scatterplot(x=reduced_data[:-num_clusters, 0], y=reduced_data[:-num_clusters, 1], size=10)#,hue=cluster_labels,palette='Set1')\n",
    "\n",
    "\n",
    "\n",
    "plt.quiver(pos_x, pos_y, u/norm, v/norm, angles=\"xy\", zorder=5, pivot=\"mid\",width=0.001,headwidth=20)\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "'''centroids = reduced_data[-num_clusters:]\n",
    "sns.scatterplot(\n",
    "    x=centroids[:, 0],\n",
    "    y=centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=600,\n",
    "    hue=np.linspace(0,num_clusters-1,num_clusters),\n",
    "    palette='Set1',\n",
    "    legend=False\n",
    ")'''\n",
    "\n",
    "\n",
    "plt.xlim(x_min-7, x_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.legend('',frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords=np.array([[-13.5,0.4],\n",
    "        [35,0.4],\n",
    "        [7,-6],\n",
    "        [7,7]])\n",
    "for coord in coords : \n",
    "    plt.figure()\n",
    "    plt.imshow(pca_2d_temp.inverse_transform(coord).reshape(76,76),cmap='viridis')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 7.5))\n",
    "\n",
    "components = pca_2d_temp.components_\n",
    "for c, comp in enumerate(components):\n",
    "    im=axs[c].imshow(comp.reshape(int(np.sqrt(len(comp))), int(np.sqrt(len(comp)))), cmap='bwr')\n",
    "    axs[c].axis('off')  # Remove axis labels for cleaner visualization\n",
    "    axs[c].set_title(f'PC {c+1}')\n",
    "\n",
    "\n",
    "# Place colorbar on the right side vertically\n",
    "cbar_ax = fig.add_axes([0.92, 0.255, 0.02, 0.47])\n",
    "\n",
    "fig.colorbar(im, cax=cbar_ax, orientation='vertical', cmap='bwr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = np.linspace(1, 2400, len(correlation_matrices_temp))\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'black', 'purple']\n",
    "\n",
    "plt.figure(figsize=(16, 8))  # Increase the figure size\n",
    "\n",
    "for a in range(num_clusters):\n",
    "    plt.plot(time, distances_temp[a, :], label=f'State {str(a)}', c=colors[a])\n",
    "\n",
    "plt.xlabel('Time [s]', fontsize=24)\n",
    "plt.ylabel('1- relative distance', fontsize=24)\n",
    "plt.legend(fontsize=20)\n",
    "plt.tick_params(axis='y', labelsize=18)\n",
    "plt.tick_params(axis='x', labelsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results dif noise, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/5min_surface/'\n",
    "for i in [2]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment29.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=300000\n",
    "\n",
    "    #source activity\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "\n",
    "    #eeg\n",
    "    id = np.where((teeg_time>=t1)*(teeg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    eeg_data = teeg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats2,most_repeating_states2, correlation_matrices2, cluster_labels2,distances2, pca2, reduced_data2 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/5min_surface/'\n",
    "for i in [5]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment29.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=300000\n",
    "\n",
    "    #source activity\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "\n",
    "    #eeg\n",
    "    id = np.where((teeg_time>=t1)*(teeg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    eeg_data = teeg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats5,most_repeating_states5, correlation_matrices5, cluster_labels5,distances5, pca5, reduced_data5 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PCs(pca5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/15Hz_2/'\n",
    "for i in [7]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment55.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=300000\n",
    "\n",
    "    #source activity\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "\n",
    "    #eeg\n",
    "    id = np.where((teeg_time>=t1)*(teeg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    eeg_data = teeg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats7_2,most_repeating_states7_2, correlation_matrices7_2, cluster_labels7_2,distances7_2, pca7_2, reduced_data7_2 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=950,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/5min_surface/'\n",
    "for i in [7]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment29.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=300000\n",
    "\n",
    "    #source activity\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "\n",
    "    #eeg\n",
    "    id = np.where((teeg_time>=t1)*(teeg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    eeg_data = teeg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods :\n",
    "        closest_mats7,most_repeating_states7, correlation_matrices7, cluster_labels7,distances7, pca7, reduced_data7 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/5min_surface/'\n",
    "for i in [8]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment29.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=300000\n",
    "\n",
    "    #source activity\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "\n",
    "    #eeg\n",
    "    id = np.where((teeg_time>=t1)*(teeg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    eeg_data = teeg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats8,most_repeating_states8, correlation_matrices8, cluster_labels8,distances8, pca8, reduced_data8 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/5min_surface/'\n",
    "for i in [9]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment29.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=300000\n",
    "\n",
    "    #source activity\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "\n",
    "    #eeg\n",
    "    id = np.where((teeg_time>=t1)*(teeg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    eeg_data = teeg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats9,most_repeating_states9, correlation_matrices9, cluster_labels9,distances9, pca9, reduced_data9 = DFC_visu_pipeline(source_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrahemispheric eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=f'D:/Fariba/5min_surface/'\n",
    "Subjects=['TVB2','TVB5','TVB7','TVB8','TVB9']#,'TVB10','TVB11','TVB12']\n",
    "right_indices=[]\n",
    "left_indices=[]\n",
    "middle_indices=[]\n",
    "ordered_ind=[]\n",
    "for i, subj in enumerate (Subjects) : \n",
    "    conn_file=file_path+subj+'/eeg_1010.txt'\n",
    "    r_ind=[]\n",
    "    l_ind=[]\n",
    "    m_ind=[]\n",
    "    with open(conn_file) as f:\n",
    "        lines = f.readlines()\n",
    "    for j, line in enumerate(lines) : \n",
    "        words = line.split()\n",
    "        # Get the first word (element before the first space)\n",
    "        first_word = words[0]\n",
    "        print(first_word)\n",
    "        if first_word[-1].isdigit() : \n",
    "            last=int(first_word[-1])\n",
    "            if last%2==0 : \n",
    "                r_ind.append(j)\n",
    "                print('right')\n",
    "            elif last%2==1 : \n",
    "                l_ind.append(j)\n",
    "                print('left')\n",
    "        else :\n",
    "                m_ind.append(j)\n",
    "                print('middle')    \n",
    "\n",
    "    right_indices.append(r_ind)\n",
    "    left_indices.append(l_ind)\n",
    "    middle_indices.append(m_ind)\n",
    "    ordered_ind.append(np.concatenate((l_ind,m_ind,r_ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_ind=np.concatenate((left_indices[1],middle_indices[1],right_indices[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVB2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all subjects eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conn = f'D:/Fariba/5min_surface/'\n",
    "closest_mats_joined=[]\n",
    "for i in [2,5,7,8,9]:#[2,5,7,8,9,10,11,12]:\n",
    "    subj = 'TVB'+str(i)\n",
    "    path_data_eeg =  f'{path_conn}/{subj}/'\n",
    "    data = np.load(f'{path_data_eeg}/segment29.npz')\n",
    "    savg_time = data['savg_time']\n",
    "    savg_data = data['savg_data']\n",
    "    teeg_time = data['eeg_time']\n",
    "    teeg_data = data['eeg_data']\n",
    "    \n",
    "    # desired ouput \n",
    "    savg_y1y2 = savg_data[:, 1, :, 0]-savg_data[:, 2, :, 0]\n",
    "    teeg_y1y2 = (teeg_data[:, 1, :, 0]-teeg_data[:, 2, :, 0])\n",
    "    \n",
    "    t1=1000\n",
    "    t2=300000\n",
    "\n",
    "    #source activity\n",
    "    id = np.where((savg_time>=t1)*(savg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    source_data = savg_y1y2[idt1:idt2]\n",
    "\n",
    "    #eeg\n",
    "    id = np.where((teeg_time>=t1)*(teeg_time<=t2))\n",
    "    idt1 = id[0][0]\n",
    "    idt2 = id[0][-1]\n",
    "    \n",
    "    eeg_data = teeg_y1y2[idt1:idt2]\n",
    "    \n",
    "    print(np.array(source_data).shape)\n",
    "\n",
    "    methods=['Pearson']#,'Spearman', 'Coherence', 'Phase-lock' ] #'Pearson', 'Coherence','Cross-cor'\n",
    "    for meth in methods : \n",
    "        closest_mats,most_repeating_states, correlation_matrices, cluster_labels,distances, pca, reduced_data = DFC_visu_pipeline(eeg_data,meth,animated_visu=False, window_size=1000,overlap=500,tmax=t2/1000, intrahemispheric=False)\n",
    "    closest_mats_joined.append(closest_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, subj in enumerate([2,5,7,8,9]):\n",
    "    plt.figure()\n",
    "    plt.imshow(closest_mats_joined[i][0][ordered_ind][ordered_ind],cmap='viridis')\n",
    "    plt.title(f'Subject {subj}')\n",
    "    plt.colorbar()\n",
    "    plt.clim([0,1])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_mats_joined[i][0][ordered_ind].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_closest_mats_joined = []\n",
    "for i,closest_mats in enumerate(closest_mats_joined):\n",
    "    ordered_closest_mats = []\n",
    "    for matrix in closest_mats:\n",
    "        ordered_matrix = matrix[ordered_ind[i]][:, ordered_ind[i]]\n",
    "        ordered_closest_mats.append(ordered_matrix)\n",
    "    ordered_closest_mats_joined.append(ordered_closest_mats)\n",
    "\n",
    "for i, subj in enumerate([2,5,7,8,9]):\n",
    "    for j in range(3):\n",
    "        plt.figure()\n",
    "        plt.imshow(ordered_closest_mats_joined[i][j],cmap='viridis')\n",
    "        plt.title(f'Subject {subj}')\n",
    "        plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_mats_joined = np.array(closest_mats_joined)\n",
    "closest_mats_joined.shape\n",
    "for i in closest_mats_joined:\n",
    "    print(i.shape)\n",
    "    for j in i: \n",
    "        print(j.shape) \n",
    "        print(j[ordered_ind][:, ordered_ind].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_closest_mats_joined = np.array(ordered_closest_mats_joined)\n",
    "ordered_closest_mats_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_ind[i].shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
